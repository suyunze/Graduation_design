C:\Users\yjysy\AppData\Local\Programs\Python\Python37\python.exe "D:/pythonProject/Graduation design/LSTM.py"
连接MySQL数据库成功
D:/pythonProject/Graduation design/LSTM.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\torch\csrc\utils\tensor_new.cpp:201.)
  target_stock_data = torch.Tensor(target_stock_data)
torch.Size([5000, 2])
Epoch: 0  loss:  0.0003565726219676435
Epoch: 1  loss:  0.00016359238361474127
Epoch: 2  loss:  0.0002592953387647867
Epoch: 3  loss:  0.00018826324958354235
Epoch: 4  loss:  0.00033867682213895023
Epoch: 5  loss:  0.0002236872969660908
Epoch: 6  loss:  0.0002991829824168235
Epoch: 7  loss:  0.0002729958505369723
Epoch: 8  loss:  0.0001969592849491164
Epoch: 9  loss:  0.00014034063497092575
Epoch: 10  loss:  8.56816113810055e-05
Epoch: 11  loss:  0.00014826911501586437
Epoch: 12  loss:  0.000242482332396321
Epoch: 13  loss:  0.0003324444987811148
Epoch: 14  loss:  0.00012626875832211226
Epoch: 15  loss:  0.000164502183906734
Epoch: 16  loss:  0.00013372367538977414
Epoch: 17  loss:  0.00026446321862749755
Epoch: 18  loss:  0.00018922878371085972
Epoch: 19  loss:  3.6663659557234496e-05
Epoch: 20  loss:  0.00010323837341275066
Epoch: 21  loss:  0.00016056711319833994
Epoch: 22  loss:  0.00014724471839144826
Epoch: 23  loss:  0.00016855716239660978
Epoch: 24  loss:  0.00011445426935097203
Epoch: 25  loss:  0.000261290289927274
Epoch: 26  loss:  0.00010113289317814633
Epoch: 27  loss:  0.0001555017224745825
Epoch: 28  loss:  0.0001259138953173533
Epoch: 29  loss:  0.00026770966360345483
Epoch: 30  loss:  6.160472548799589e-05
Epoch: 31  loss:  5.757835606345907e-05
Epoch: 32  loss:  0.0003243796236347407
Epoch: 33  loss:  0.00010741683945525438
Epoch: 34  loss:  6.288462463999167e-05
Epoch: 35  loss:  0.0001729473879095167
Epoch: 36  loss:  9.500744636170566e-05
Epoch: 37  loss:  0.00016573959146626294
Epoch: 38  loss:  0.00026542184059508145
Epoch: 39  loss:  0.00012482330203056335
Epoch: 40  loss:  0.00022787963098380715
Epoch: 41  loss:  0.00018215933232568204
Epoch: 42  loss:  0.00022293503570836037
Epoch: 43  loss:  0.00017153022054117173
Epoch: 44  loss:  0.0002567293413449079
Epoch: 45  loss:  0.0002138708223355934
Epoch: 46  loss:  0.0002087444590870291
Epoch: 47  loss:  0.00012249706196598709
Epoch: 48  loss:  0.0003160757478326559
Epoch: 49  loss:  0.0004148319421801716
Epoch: 50  loss:  0.000186489152838476
Epoch: 51  loss:  0.0001222820719704032
Epoch: 52  loss:  0.00011104914301540703
Epoch: 53  loss:  8.73443714226596e-05
Epoch: 54  loss:  0.00014376577746588737
Epoch: 55  loss:  0.00024988874793052673
Epoch: 56  loss:  0.00026477669598534703
Epoch: 57  loss:  0.0004312685923650861
Epoch: 58  loss:  0.00016653987404424697
Epoch: 59  loss:  0.00012291203893255442
Epoch: 60  loss:  8.061164407990873e-05
Epoch: 61  loss:  0.00027966834022663534
Epoch: 62  loss:  0.0001481965882703662
Epoch: 63  loss:  0.0004360227903816849
Epoch: 64  loss:  9.257951751351357e-05
Epoch: 65  loss:  8.674996206536889e-05
Epoch: 66  loss:  0.00015619618352502584
Epoch: 67  loss:  0.00017394694441463798
Epoch: 68  loss:  0.00022715779778081924
Epoch: 69  loss:  9.314737690147012e-05
Epoch: 70  loss:  0.00014310295227915049
Epoch: 71  loss:  0.00012618704931810498
Epoch: 72  loss:  9.309370943810791e-05
Epoch: 73  loss:  0.0002750222629401833
Epoch: 74  loss:  0.00010595819912850857
Epoch: 75  loss:  0.0002502794377505779
Epoch: 76  loss:  0.00013861026673112065
Epoch: 77  loss:  0.0003705232811626047
Epoch: 78  loss:  0.0001573694171383977
Epoch: 79  loss:  0.00021510371880140156
Epoch: 80  loss:  0.00023803416115697473
Epoch: 81  loss:  7.781883323332295e-05
Epoch: 82  loss:  0.00024167737865354866
Epoch: 83  loss:  0.00015184332733042538
Epoch: 84  loss:  0.00017537748499307781
Epoch: 85  loss:  6.703541293973103e-05
Epoch: 86  loss:  0.00012345894356258214
Epoch: 87  loss:  0.00020395936735440046
Epoch: 88  loss:  7.038535113679245e-05
Epoch: 89  loss:  8.904412970878184e-05
Epoch: 90  loss:  0.00016258866526186466
Epoch: 91  loss:  0.0001259017881238833
Epoch: 92  loss:  0.0001233256043633446
Epoch: 93  loss:  0.00012890617654193193
Epoch: 94  loss:  0.00012221603537909687
Epoch: 95  loss:  0.00017035732162185013
Epoch: 96  loss:  0.000291517935693264
Epoch: 97  loss:  0.00013361709716264158
Epoch: 98  loss:  0.00013427594967652112
Epoch: 99  loss:  0.00022334989625960588
Epoch: 100  loss:  0.00025255128275603056
Epoch: 101  loss:  0.00023970501206349581
Epoch: 102  loss:  0.00027042001602239907
Epoch: 103  loss:  0.000255154533078894
Epoch: 104  loss:  0.00019274587975814939
Epoch: 105  loss:  0.00012105754285585135
Epoch: 106  loss:  6.80045923218131e-05
Epoch: 107  loss:  0.0001265055179828778
Epoch: 108  loss:  0.00013633961498271674
Epoch: 109  loss:  0.0001309865474468097
Epoch: 110  loss:  0.0001638665999053046
Epoch: 111  loss:  0.00014407795970328152
Epoch: 112  loss:  7.879563054302707e-05
Epoch: 113  loss:  0.00018795875075738877
Epoch: 114  loss:  0.0001883553632069379
Epoch: 115  loss:  0.00020853999012615532
Epoch: 116  loss:  8.694471762282774e-05
Epoch: 117  loss:  0.00018445697787683457
Epoch: 118  loss:  0.0002990690991282463
Epoch: 119  loss:  0.00016875921573955566
Epoch: 120  loss:  9.100721217691898e-05
Epoch: 121  loss:  0.0002405181439826265
Epoch: 122  loss:  7.55465152906254e-05
Epoch: 123  loss:  0.0003326870792079717
Epoch: 124  loss:  0.00013739844143856317
Epoch: 125  loss:  0.00017829153512138873
Epoch: 126  loss:  0.00020448825671337545
Epoch: 127  loss:  0.00021561655739787966
Epoch: 128  loss:  0.00013233897334430367
Epoch: 129  loss:  0.00018115111743099988
Epoch: 130  loss:  0.0001915182510856539
Epoch: 131  loss:  8.091459312709048e-05
Epoch: 132  loss:  0.0001624357100808993
Epoch: 133  loss:  0.00010504414967726916
Epoch: 134  loss:  8.111404167721048e-05
Epoch: 135  loss:  0.0001556483912281692
Epoch: 136  loss:  6.539339665323496e-05
Epoch: 137  loss:  0.00012491382949519902
Epoch: 138  loss:  0.00013600099191535264
Epoch: 139  loss:  7.207237649708986e-05
Epoch: 140  loss:  0.00020128155301790684
Epoch: 141  loss:  0.0004000942572019994
Epoch: 142  loss:  8.142169826896861e-05
Epoch: 143  loss:  0.00013576245692092925
Epoch: 144  loss:  0.00033718618215061724
Epoch: 145  loss:  9.383955330122262e-05
Epoch: 146  loss:  0.00016046686505433172
Epoch: 147  loss:  0.0001634882646612823
Epoch: 148  loss:  0.00011357058247085661
Epoch: 149  loss:  4.887966133537702e-05
acc:  tensor(0.4375)
acc:  tensor(0.4844)
acc:  tensor(0.4688)
acc:  tensor(0.3750)
[(1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0)]
time:  40.32344937324524

进程已结束,退出代码0
